{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "output_dir = '../outputs/'\n",
    "output_prefix = 'taka-toolo_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, dirs, files in os.walk(data_dir):\n",
    "    break\n",
    "\n",
    "for i, fn in enumerate(files):\n",
    "    print(i, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_file = 'taka-toolo-roads.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + road_file, 'r') as fo:\n",
    "    roads_raw = fo.read().split('\\n')\n",
    "    \n",
    "len(roads_raw), roads_raw[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def length_of_longest(roads_raw):\n",
    "    return max([\n",
    "        len(rn) for rn in roads_raw\n",
    "    ])\n",
    "longest_rn = length_of_longest(roads_raw)\n",
    "longest_rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finnish words corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = dirs[0] + '/kotus-sanalista_v1.xml'\n",
    "corpus_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir + corpus_file, 'r') as fo:\n",
    "    content = fo.read().split('\\n')\n",
    "    \n",
    "    content = ''.join(content)\n",
    "    bs_content = bs(content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = [tag.contents[0] for tag in bs_content.find_all('s')]\n",
    "corpus_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_set = set(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building palindromes from the road names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use letters several times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = roads_raw[0]\n",
    "rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toString(List):\n",
    "    return ''.join(List)\n",
    " \n",
    "# Function to print permutations of string\n",
    "# This function takes three parameters:\n",
    "# 1. String\n",
    "# 2. Starting index of the string\n",
    "# 3. Ending index of the string.\n",
    "def permute(a, l, r, perms:list):\n",
    "    if l==r:\n",
    "        perms.append(toString(a))\n",
    "    else:\n",
    "        for i in range(l,r+1):\n",
    "            a[l], a[i] = a[i], a[l]\n",
    "            permute(a, l+1, r, perms)\n",
    "            a[l], a[i] = a[i], a[l] # backtrack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = []\n",
    "permute(list('aur'), 0, len('aur')-1, perm)\n",
    "perm = sorted(list(set(perm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_permutations(string, up_to_n = 7):\n",
    "    perms = []\n",
    "    top = min(len(string), up_to_n)\n",
    "    for i in range(1, top+1):\n",
    "        print(f'permutations of length {i}/{len(string)}', end='\\r')\n",
    "        perms += [\n",
    "            ''.join(comb) for comb in product(list(string), repeat=i)\n",
    "        ]\n",
    "        \n",
    "    print('done!                                         ')\n",
    "\n",
    "    return sorted(list(set(perms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rn)\n",
    "perms = all_permutations(rn.lower(), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take only palindromes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_palindrome(s):\n",
    "    is_pali = True\n",
    "\n",
    "    l = len(s)\n",
    "    for i in range(l // 2 + l % 2):\n",
    "        #print(i, s[i], s[-i-1])\n",
    "        if s[i] != s[-i-1]:\n",
    "            is_pali=False\n",
    "            break\n",
    "\n",
    "    return is_pali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_palindromes(candidates):\n",
    "    pali_mask = [\n",
    "        is_palindrome(s) for s in candidates\n",
    "    ]\n",
    "\n",
    "    palinds = np.array(candidates)[pali_mask]\n",
    "    return palinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palinds = filter_palindromes(perms)\n",
    "palinds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check which ones include words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(candidates, corpus_set):\n",
    "    is_word_mask = [\n",
    "        c in corpus_set for c in candidates\n",
    "    ]\n",
    "\n",
    "    words = np.array(candidates)[is_word_mask]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words(palinds, corpus_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palindromes for all roads in one area, letters can be reused "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabs(rn:str, longest_rn:int, tab=6):\n",
    "    t_str = ((longest_rn - len(rn)) // tab + 1) * ['\\t']\n",
    "    t_str = ''.join(t_str)\n",
    "    return t_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def meaningful_palindromes(road_names, corpus_set, up_to_n=7, verbose = False):\n",
    "    words = {}\n",
    "    longest_rn = length_of_longest(road_names)\n",
    "    \n",
    "    for i, rn in enumerate(road_names):\n",
    "        t_str = get_tabs(rn, longest_rn)\n",
    "        if verbose: print(f'{rn}{t_str} {i+1}/{len(road_names)}')\n",
    "\n",
    "        perms = all_permutations(rn.lower(), up_to_n)\n",
    "        palinds = filter_palindromes(perms)\n",
    "        words[rn] = filter_words(palinds, corpus_set)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(words):\n",
    "    return sorted(list(set(np.concatenate(list(words.values())).tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_to_n = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "words = meaningful_palindromes(roads_raw, \n",
    "                               corpus_set,\n",
    "                               up_to_n=up_to_n, \n",
    "                               verbose=True)\n",
    "words_unique = get_unique_values(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'for {len(words)} road names we found {len(words_unique)} unique, meaningful palindroms with max length of {up_to_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "road2n = {\n",
    "    key: len(words[key]) for key in words\n",
    "}\n",
    "\n",
    "road2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "road2words = {\n",
    "    key: ', '.join(words[key]) for key in words\n",
    "}\n",
    "\n",
    "road2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results to DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(road2n, index=['n_words']).T.reset_index().rename(columns={'index': 'street'})\n",
    "df_words['words'] = list(road2words.values())\n",
    "\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.sort_values('n_words', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.to_csv(output_dir + output_prefix + 'palindrome_words_by_street.csv')\n",
    "with open(output_dir + output_prefix + 'palindrome_words_unique.txt', 'w') as fo:\n",
    "    fo.write('\\n'.join(words_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaningful words from letters available in one road name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def meaningful_words(road_names, corpus_set, up_to_n=7, verbose=True):\n",
    "    words = {}\n",
    "    longest_rn = length_of_longest(road_names)\n",
    "    \n",
    "    for i, rn in enumerate(road_names):\n",
    "        t_str = get_tabs(rn, longest_rn)\n",
    "        if verbose: print(f'{rn}{t_str} {i+1}/{len(road_names)}')\n",
    "\n",
    "        perms = all_permutations(rn.lower(), up_to_n)\n",
    "        words[rn] = filter_words(perms, corpus_set)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "words_all = meaningful_words(roads_raw, corpus_set,\n",
    "                        up_to_n=up_to_n, \n",
    "                        verbose=True)\n",
    "\n",
    "words_all_unique = get_unique_values(words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'for {len(roads_raw)} road names we found {len(words_all_unique)} unique words with max length of {up_to_n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use letter only once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palindromeSubStrs(s):\n",
    "    m = dict()\n",
    "    n = len(s)\n",
    "  \n",
    "    # table for storing results (2 rows for odd-\n",
    "    # and even-length palindromes\n",
    "    R = [[0 for x in range(n+1)] for x in range(2)]\n",
    "  \n",
    "    # Find all sub-string palindromes from the given input\n",
    "    # string insert 'guards' to iterate easily over s\n",
    "    s = \"@\" + s + \"#\"\n",
    "\n",
    "    for j in range(2):\n",
    "        rp = 0    # length of 'palindrome radius'\n",
    "        R[j][0] = 0\n",
    "  \n",
    "        i = 1\n",
    "        while i <= n:\n",
    "  \n",
    "            # Attempt to expand palindrome centered at i\n",
    "            while s[i - rp - 1] == s[i + j + rp]:\n",
    "                rp += 1 # Incrementing the length of palindromic\n",
    "                        # radius as and when we find valid palindrome\n",
    "  \n",
    "            # Assigning the found palindromic length to odd/even\n",
    "            # length array\n",
    "            R[j][i] = rp\n",
    "            k = 1\n",
    "            while (R[j][i - k] != rp - k) and (k < rp):\n",
    "                R[j][i+k] = min(R[j][i-k], rp - k)\n",
    "                k += 1\n",
    "            rp = max(rp - k, 0)\n",
    "            i += k\n",
    "  \n",
    "    # remove guards\n",
    "    s = s[1:len(s)-1]\n",
    "  \n",
    "    # Put all obtained palindromes in a hash map to\n",
    "    # find only distinct palindrome\n",
    "    m[s[0]] = 1\n",
    "    for i in range(1,n):\n",
    "        for j in range(2):\n",
    "            for rp in range(R[j][i],0,-1):\n",
    "                m[s[i - rp - 1 : i - rp - 1 + 2 * rp + j]] = 1\n",
    "        m[s[i]] = 1\n",
    "  \n",
    "    \n",
    "    return sorted(list(m.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palinds_use_letters_once(road_names):\n",
    "    palinds = {}\n",
    "    \n",
    "    for rn in road_names:\n",
    "        palinds[rn] = palindromeSubStrs(rn.lower())\n",
    "\n",
    "    return palinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palinds = palinds_use_letters_once(roads_raw)\n",
    "\n",
    "palinds_unique = get_unique_values(palinds)\n",
    "palinds_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words(palinds_unique, corpus_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "81fa6bc5d29927c7b928f78b296e354fe27653493ad47fd05ffb6854094dc5c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
